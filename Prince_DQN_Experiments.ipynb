{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bd6ccf",
   "metadata": {},
   "source": [
    "# Prince's DQN Atari Experiments\n",
    "\n",
    "This notebook runs 10 unique Deep Q-Learning experiments on different Atari games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c864b61",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082dd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing required packages...\")\n",
    "!pip uninstall numpy -y -q\n",
    "\n",
    "print(\"Installing compatible numpy...\")\n",
    "!pip install \"numpy>=1.26.0,<2.1\" --force-reinstall -q\n",
    "\n",
    "print(\"\\nVerifying installations...\")\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "from stable_baselines3 import DQN\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "print(f\"Gymnasium version: {gym.__version__}\")\n",
    "print(f\"ALE-Py version: {ale_py.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Numpy version: {numpy.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609fdfaf",
   "metadata": {},
   "source": [
    "## Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "train_script = '''import argparse\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "import os\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "def create_atari_env(env_name):\n",
    "    def _init():\n",
    "        env = gym.make(env_name, render_mode=None)\n",
    "        env = AtariWrapper(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "def train_dqn(env_name, total_timesteps, learning_rate, gamma, batch_size, \n",
    "              exploration_initial_eps, exploration_final_eps, exploration_fraction, \n",
    "              experiment_name):\n",
    "    \n",
    "    print(f\"Starting experiment: {experiment_name}\")\n",
    "    print(f\"Environment: {env_name}\")\n",
    "    print(f\"Timesteps: {total_timesteps:,}\")\n",
    "    print(f\"Hyperparameters:\")\n",
    "    print(f\"  LR: {learning_rate}, Gamma: {gamma}, Batch: {batch_size}\")\n",
    "    print(f\"  Exploration: {exploration_initial_eps} -> {exploration_final_eps}\")\n",
    "    \n",
    "    env = DummyVecEnv([create_atari_env(env_name)])\n",
    "    env = VecFrameStack(env, n_stack=4)\n",
    "    \n",
    "    log_dir = f\"logs/{experiment_name}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Adjust parameters for short runs\n",
    "    buffer_size = min(50000, total_timesteps)\n",
    "    learning_starts = min(1000, total_timesteps // 10)\n",
    "    checkpoint_freq = max(5000, total_timesteps // 2)\n",
    "    \n",
    "    model = DQN(\n",
    "        \"CnnPolicy\",\n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        gamma=gamma,\n",
    "        batch_size=batch_size,\n",
    "        buffer_size=buffer_size,\n",
    "        learning_starts=learning_starts,\n",
    "        target_update_interval=500,\n",
    "        exploration_initial_eps=exploration_initial_eps,\n",
    "        exploration_final_eps=exploration_final_eps,\n",
    "        exploration_fraction=exploration_fraction,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        verbose=1,\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=checkpoint_freq,\n",
    "        save_path=f\"models/{experiment_name}\",\n",
    "        name_prefix=\"dqn\"\n",
    "    )\n",
    "    \n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=[checkpoint_callback],\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    model_path = f\"models/{experiment_name}_final.zip\"\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    env.close()\n",
    "    return model_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--env\", type=str, required=True)\n",
    "    parser.add_argument(\"--timesteps\", type=int, default=10000)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eps-start\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--eps-end\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--exp-fraction\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--experiment\", type=str, required=True)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_dqn(\n",
    "        env_name=args.env,\n",
    "        total_timesteps=args.timesteps,\n",
    "        learning_rate=args.lr,\n",
    "        gamma=args.gamma,\n",
    "        batch_size=args.batch_size,\n",
    "        exploration_initial_eps=args.eps_start,\n",
    "        exploration_final_eps=args.eps_end,\n",
    "        exploration_fraction=args.exp_fraction,\n",
    "        experiment_name=args.experiment\n",
    "    )\n",
    "'''\n",
    "\n",
    "with open('train.py', 'w') as f:\n",
    "    f.write(train_script)\n",
    "\n",
    "print(\"Training script created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01058cc7",
   "metadata": {},
   "source": [
    "## Step 3: Define Experiments\n",
    "\n",
    "Currently set to 10,000 timesteps for quick testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to 1000000 for full training\n",
    "TIMESTEPS = 10000\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"prince_exp_1_seaquest_baseline\",\n",
    "        \"env\": \"ALE/Seaquest-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"Baseline with standard hyperparameters\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_2_asterix_high_lr\",\n",
    "        \"env\": \"ALE/Asterix-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"High learning rate test\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_3_boxing_low_gamma\",\n",
    "        \"env\": \"ALE/Boxing-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.95,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"Low gamma for short-term rewards\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_4_krull_large_batch\",\n",
    "        \"env\": \"ALE/Krull-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 128,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"Large batch size for stability\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_5_riverraid_extended_exploration\",\n",
    "        \"env\": \"ALE/Riverraid-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.3,\n",
    "        \"description\": \"Extended exploration phase\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_6_qbert_high_gamma\",\n",
    "        \"env\": \"ALE/Qbert-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.995,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"High gamma for long-term planning\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_7_mspacman_combined\",\n",
    "        \"env\": \"ALE/MsPacman-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0003,\n",
    "        \"gamma\": 0.98,\n",
    "        \"batch_size\": 64,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.2,\n",
    "        \"description\": \"Balanced hyperparameters\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_8_zaxxon_very_large_batch\",\n",
    "        \"env\": \"ALE/Zaxxon-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 256,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.1,\n",
    "        \"description\": \"Very large batch size\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_9_battlezone_slow_exploration\",\n",
    "        \"env\": \"ALE/BattleZone-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"gamma\": 0.99,\n",
    "        \"batch_size\": 32,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.05,\n",
    "        \"exploration_fraction\": 0.5,\n",
    "        \"description\": \"Very slow exploration decay\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prince_exp_10_frostbite_aggressive\",\n",
    "        \"env\": \"ALE/Frostbite-v5\",\n",
    "        \"timesteps\": TIMESTEPS,\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"gamma\": 0.98,\n",
    "        \"batch_size\": 128,\n",
    "        \"exploration_initial_eps\": 1.0,\n",
    "        \"exploration_final_eps\": 0.02,\n",
    "        \"exploration_fraction\": 0.15,\n",
    "        \"description\": \"Aggressive hyperparameters\"\n",
    "    }\n",
    "]\n",
    "\n",
    "mode_text = \"TEST MODE (10K timesteps)\" if TIMESTEPS == 10000 else \"FULL MODE (1M timesteps)\"\n",
    "estimated_time = \"10-20 minutes\" if TIMESTEPS == 10000 else \"8-12 hours\"\n",
    "\n",
    "print(f\"Mode: {mode_text}\")\n",
    "print(f\"Timesteps per experiment: {TIMESTEPS:,}\")\n",
    "print(f\"Estimated total time: {estimated_time}\")\n",
    "print(f\"\\nDefined {len(EXPERIMENTS)} experiments:\")\n",
    "for i, exp in enumerate(EXPERIMENTS, 1):\n",
    "    print(f\"{i}. {exp['name']}: {exp['env']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b5d75",
   "metadata": {},
   "source": [
    "## Run All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c66d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"Starting {len(EXPERIMENTS)} experiments at {datetime.now()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, exp in enumerate(EXPERIMENTS, 1):\n",
    "    print(f\"\\n[{i}/{len(EXPERIMENTS)}] {exp['name']}\")\n",
    "    print(f\"Environment: {exp['env']}\")\n",
    "    print(f\"Timesteps: {exp['timesteps']:,}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    cmd = [\n",
    "        'python', 'train.py',\n",
    "        '--env', exp['env'],\n",
    "        '--timesteps', str(exp['timesteps']),\n",
    "        '--lr', str(exp['learning_rate']),\n",
    "        '--gamma', str(exp['gamma']),\n",
    "        '--batch-size', str(exp['batch_size']),\n",
    "        '--eps-start', str(exp['exploration_initial_eps']),\n",
    "        '--eps-end', str(exp['exploration_final_eps']),\n",
    "        '--exp-fraction', str(exp['exploration_fraction']),\n",
    "        '--experiment', exp['name']\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'experiment': exp['name'],\n",
    "            'env': exp['env'],\n",
    "            'status': 'completed',\n",
    "            'timesteps': exp['timesteps'],\n",
    "            'duration_seconds': elapsed_time,\n",
    "            'duration_minutes': f\"{elapsed_time/60:.1f}\",\n",
    "            'hyperparameters': {\n",
    "                'learning_rate': exp['learning_rate'],\n",
    "                'gamma': exp['gamma'],\n",
    "                'batch_size': exp['batch_size'],\n",
    "                'exploration_fraction': exp['exploration_fraction']\n",
    "            },\n",
    "            'description': exp['description']\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nCompleted in {elapsed_time/60:.1f} minutes\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        results.append({\n",
    "            'experiment': exp['name'],\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nAll experiments completed at {datetime.now()}\")\n",
    "\n",
    "with open('experiment_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to experiment_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7d96c",
   "metadata": {},
   "source": [
    "## View Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('experiment_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "completed = [r for r in results if r['status'] == 'completed']\n",
    "failed = [r for r in results if r['status'] == 'failed']\n",
    "\n",
    "print(f\"\\nCompleted: {len(completed)}/{len(results)}\")\n",
    "if failed:\n",
    "    print(f\"Failed: {len(failed)}\")\n",
    "\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {result['experiment']}\")\n",
    "    print(f\"   Environment: {result['env']}\")\n",
    "    print(f\"   Status: {result['status']}\")\n",
    "    if result['status'] == 'completed':\n",
    "        print(f\"   Duration: {result['duration_minutes']} minutes\")\n",
    "        print(f\"   Timesteps: {result['timesteps']:,}\")\n",
    "        print(f\"   Description: {result['description']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f0b8e",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a62f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"Creating ZIP archives...\")\n",
    "\n",
    "if os.path.exists('models'):\n",
    "    shutil.make_archive('prince_models', 'zip', 'models')\n",
    "    print(\"Created: prince_models.zip\")\n",
    "\n",
    "if os.path.exists('logs'):\n",
    "    shutil.make_archive('prince_logs', 'zip', 'logs')\n",
    "    print(\"Created: prince_logs.zip\")\n",
    "\n",
    "print(\"\\nFiles ready for download:\")\n",
    "print(\"- experiment_results.json\")\n",
    "print(\"- prince_models.zip\")\n",
    "print(\"- prince_logs.zip\")\n",
    "print(\"\\nUse the file browser on the left to download.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
